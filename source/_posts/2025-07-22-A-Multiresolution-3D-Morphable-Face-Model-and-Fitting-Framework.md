---
title: A Multiresolution 3D Morphable Face Model and Fitting Framework
date: 2025-07-22 17:55:55
categories:
- Reading Notes
- 3dmm
tags: 
- Reading Notes
- 3dmm
---

# 贡献
提供了名为SFM（Surrey Face Model）的人脸模型，包含不同的分辨率层次和标注landmarks，让人脸模型的拟合更快；同时开源了一个3DMM人脸重建的代码框架，促进社区的研究。
- [Surrey Face Model](https://cvssp.org/faceweb/3dmm/facemodels/)，包括开源非商用版本和商用版本
- [eos: A lightweight header-only 3D Morphable Face Model fitting library](https://github.com/patrikhuber/eos)，代码框架

# 数据集

使用[3dMDface](https://3dmd.com/)相机系统采集，并用Iterative Multi-resolution Dense 3D Registration (IMDR) method (Tena et al., 2006)配准及细分操作，生成不同分辨率的人脸3D模型。低分辨率网格顶点在高分辨率网格中依然存在，且序号一致。

# 标注

PCA结果主成分中，保留了63个网格特征向量和132个颜色特征向量，这样重建模型能保留99%的原始数据变化。特征向量和特征值都预存到数据文件中了。
论文公布了常用的landmars标注数据，代码中使用了`[ibug](http://ibug.doc.ic.ac.uk/resources/facial-point-annotations/)`人脸点标注。

# 纹理贴图

- 表示方法：isomap algorithm (Tenenbaum et al., 2000): it finds a projection from the 3D vertices to a 2D plane that preserves the geodesic distance between the mesh vertices. 
- 映射算法：Rodr ́ıguez, 2007, 3D Face Modelling for 2D+3D Face Recognition. PhD thesis

# 具体实现

- Pose Estimation：Gold Standard Algorithm of Hartley & Zisserman (Hartley and Zisserman, 2004)，假设放摄像机模型`affine camera`
- Shape Fitting：Aldrian, O. and Smith, W. A. P. (2013). Inverse rendering of faces with a 3D Morphable Model.

# Annotations

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2FEIWKIWKF%22%2C%22annotationKey%22%3A%22VYC8VL4V%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B501.756%2C529.165%2C521.581%2C537.181%5D%2C%5B129.175%2C518.206%2C243.775%2C526.222%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%221%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/EIWKIWKF?page=1&#x26;annotation=VYC8VL4V">“facial landmark detection and tracking”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/4GDBRS3R">Huber et al., 2016, p. 1</a></span>)</span> 🔤面部地标检测和跟踪🔤

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2FEIWKIWKF%22%2C%22annotationKey%22%3A%22FSRUCHE9%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B240.511%2C496.288%2C467.603%2C504.304%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%221%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/EIWKIWKF?page=1&#x26;annotation=FSRUCHE9">“Surrey Face Model, a multi-resolution 3D Morphable Model”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/4GDBRS3R">Huber et al., 2016, p. 1</a></span>)</span> 🔤萨里面模型，一个多分辨率3D形态模型🔤

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2FEIWKIWKF%22%2C%22annotationKey%22%3A%22J5C9NW2X%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B329.951%2C485.329%2C521.581%2C493.345%5D%2C%5B129.175%2C474.37%2C403.385%2C482.386%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%221%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/EIWKIWKF?page=1&#x26;annotation=J5C9NW2X">“The model contains different mesh resolution levels and landmark point annotations as well as metadata for texture remapping”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/4GDBRS3R">Huber et al., 2016, p. 1</a></span>)</span> 🔤该模型包含不同的网格分辨率水平和具有里程碑意义的点注释以及用于纹理重新映射的元数据🔤

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2FEIWKIWKF%22%2C%22annotationKey%22%3A%228TQ2H7V5%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B508.723%2C441.493%2C521.581%2C449.509%5D%2C%5B129.175%2C430.535%2C199.247%2C438.551%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%221%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/EIWKIWKF?page=1&#x26;annotation=8TQ2H7V5">“fast fitting functionality”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/4GDBRS3R">Huber et al., 2016, p. 1</a></span>)</span> 🔤快速拟合功能🔤

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2FEIWKIWKF%22%2C%22annotationKey%22%3A%228ZUFALM6%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B282.886%2C419.576%2C521.581%2C427.592%5D%2C%5B129.175%2C408.617%2C159.042%2C416.633%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%221%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/EIWKIWKF?page=1&#x26;annotation=8ZUFALM6">“for the community to adopt the 3D Morphable Face Model in their research”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/4GDBRS3R">Huber et al., 2016, p. 1</a></span>)</span> 🔤让社区在他们的研究中采用3D可变形的面部模型🔤

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2FEIWKIWKF%22%2C%22annotationKey%22%3A%22VDJ4YAAT%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B359.854%2C330.246%2C439.784%2C339.153%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%221%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/EIWKIWKF?page=1&#x26;annotation=VDJ4YAAT">“spherical harmonics”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/4GDBRS3R">Huber et al., 2016, p. 1</a></span>)</span> 🔤球形谐波🔤

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2FEIWKIWKF%22%2C%22annotationKey%22%3A%22JFGNVTTB%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B94.762%2C466.957%2C286.313%2C475.864%5D%2C%5B73.701%2C455.499%2C286.323%2C464.406%5D%2C%5B73.701%2C444.042%2C286.323%2C452.949%5D%2C%5B73.701%2C432.585%2C93.895%2C441.492%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%222%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/EIWKIWKF?page=2&#x26;annotation=JFGNVTTB">“while the BFM provides the model, they only provide fitting results for limited databases and do not provide algorithms to apply the model to novel images.”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/4GDBRS3R">Huber et al., 2016, p. 2</a></span>)</span> 🔤尽管BFM提供了模型，但它们仅为有限的数据库提供合适的结果，并且不提供将模型应用于新图像的算法。🔤

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2FEIWKIWKF%22%2C%22annotationKey%22%3A%22K45XDXEW%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B500.851%2C606.203%2C521.613%2C615.11%5D%2C%5B308.995%2C594.746%2C445.383%2C603.653%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%222%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/EIWKIWKF?page=2&#x26;annotation=K45XDXEW">“First, we present the Surrey Face Model”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/4GDBRS3R">Huber et al., 2016, p. 2</a></span>)</span> 🔤首先，我们介绍萨里的脸模型🔤

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2FEIWKIWKF%22%2C%22annotationKey%22%3A%22DJVXMEPW%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B475.42%2C571.832%2C521.617%2C580.739%5D%2C%5B308.995%2C560.375%2C521.617%2C569.282%5D%2C%5B308.995%2C548.918%2C390.878%2C557.825%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%222%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/EIWKIWKF?page=2&#x26;annotation=DJVXMEPW">“Second, we present a lightweight open-source Morphable Model software framework”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/4GDBRS3R">Huber et al., 2016, p. 2</a></span>)</span> 🔤其次，我们提出了一个轻巧的开源形式模型软件框架🔤

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2FEIWKIWKF%22%2C%22annotationKey%22%3A%22839YF5GU%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B385.837%2C526.004%2C521.617%2C534.911%5D%2C%5B308.995%2C514.547%2C510.289%2C523.454%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%222%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/EIWKIWKF?page=2&#x26;annotation=839YF5GU">“Lastly, we make a low resolution shape model available together with the software”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/4GDBRS3R">Huber et al., 2016, p. 2</a></span>)</span> 🔤最后，我们将低分辨率形状模型与软件一起使用🔤

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2FEIWKIWKF%22%2C%22annotationKey%22%3A%226NDX6FIH%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B136.734%2C586.633%2C286.321%2C596.257%5D%2C%5B73.701%2C574.837%2C161.332%2C585.869%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%223%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/EIWKIWKF?page=3&#x26;annotation=6NDX6FIH">“where M ≤ n − 1 is the number of principal components”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/4GDBRS3R">Huber et al., 2016, p. 3</a></span>)</span> 🔤其中m≤n -1是主成分的数量🔤

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2FEIWKIWKF%22%2C%22annotationKey%22%3A%22NQ2FF4DH%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B73.701%2C492.072%2C286.323%2C500.979%5D%2C%5B73.701%2C480.615%2C286.323%2C489.522%5D%2C%5B73.701%2C469.158%2C285.82%2C479.924%5D%2C%5B73.701%2C457.701%2C134.204%2C466.608%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%223%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/EIWKIWKF?page=3&#x26;annotation=NQ2FF4DH">“The Surrey Face Model is built using a number of high-resolution 3D scans that were acquired at our lab. The scans were captured using a 3dMDface2 camera system”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/4GDBRS3R">Huber et al., 2016, p. 3</a></span>)</span> 🔤Surrey Face模型是使用我们实验室获得的许多高分辨率3D扫描构建的。使用3DMDFACE2相机系统捕获扫描🔤

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2FEIWKIWKF%22%2C%22annotationKey%22%3A%22APG42G93%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B122.996%2C308.534%2C286.323%2C317.441%5D%2C%5B73.701%2C297.077%2C173.387%2C305.984%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%223%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/EIWKIWKF?page=3&#x26;annotation=APG42G93">“Iterative Multi-resolution Dense 3D Registration (IMDR) method”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/4GDBRS3R">Huber et al., 2016, p. 3</a></span>)</span> 🔤迭代多分辨率密集3D注册（IMDR）方法🔤

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2FEIWKIWKF%22%2C%22annotationKey%22%3A%22AA4BELMI%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B163.902%2C210.272%2C286.323%2C219.179%5D%2C%5B73.701%2C198.815%2C286.313%2C207.722%5D%2C%5B73.701%2C187.358%2C218.278%2C196.265%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%224%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/EIWKIWKF?page=4&#x26;annotation=AA4BELMI">“we keep 63 shape eigenvectors and 132 colour eigenvectors so that 99% of the original variation of the data is preserved”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%224%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/4GDBRS3R">Huber et al., 2016, p. 4</a></span>)</span> 🔤我们保留63个形状特征向量和132个颜色特征向量，以保留99％的数据变化🔤

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2FEIWKIWKF%22%2C%22annotationKey%22%3A%22Q9PT3CZB%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B464.388%2C321.478%2C521.613%2C330.385%5D%2C%5B308.995%2C310.021%2C521.617%2C318.928%5D%2C%5B308.995%2C298.564%2C386.763%2C307.471%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%224%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/EIWKIWKF?page=4&#x26;annotation=Q9PT3CZB">“annotations of the most commonly used facial landmark points for all resolution levels”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%224%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/4GDBRS3R">Huber et al., 2016, p. 4</a></span>)</span> 🔤所有分辨率级别最常用的面部标志点的注释🔤

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2FEIWKIWKF%22%2C%22annotationKey%22%3A%22SB72J5VH%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B308.995%2C172.536%2C521.617%2C181.443%5D%2C%5B308.995%2C161.079%2C521.617%2C169.986%5D%2C%5B308.995%2C149.622%2C358.618%2C160.389%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%224%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/EIWKIWKF?page=4&#x26;annotation=SB72J5VH">“manually selected landmark points on the mesh that correspond to a subset of the popular ibug facial point annotations3”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%224%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/4GDBRS3R">Huber et al., 2016, p. 4</a></span>)</span> 🔤在网格上手动选择的地标点，与流行的Ibug面部点注释相对应🔤

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2FEIWKIWKF%22%2C%22annotationKey%22%3A%229IGHYGJ8%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%225%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B166.124%2C164.444%2C286.323%2C173.351%5D%2C%5B73.701%2C152.987%2C286.323%2C161.894%5D%2C%5B73.701%2C141.53%2C286.323%2C150.437%5D%2C%5B73.701%2C130.072%2C286.323%2C138.979%5D%2C%5B73.701%2C118.615%2C286.323%2C127.522%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%225%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/EIWKIWKF?page=5&#x26;annotation=9IGHYGJ8">“We create such a generic representation with the isomap algorithm (Tenenbaum et al., 2000): it finds a projection from the 3D vertices to a 2D plane that preserves the geodesic distance between the mesh vertices. Our mapping is computed with the algorithm from Tena (Rodr ́ıguez, 2007).”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%225%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/4GDBRS3R">Huber et al., 2016, p. 5</a></span>)</span> 🔤我们使用ISOMAP算法创建了这样的通用表示（Tenenbaum等，2000）：它发现了从3D顶点到2D平面的投影，该投影可保留网格顶点之间的地理距离。我们的映射使用Tena的算法（Rodŕıguez，2007年）。🔤

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2FEIWKIWKF%22%2C%22annotationKey%22%3A%22MBPDCBJG%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B355.54%2C614.546%2C521.617%2C623.453%5D%2C%5B308.995%2C603.089%2C521.615%2C611.996%5D%2C%5B308.995%2C591.632%2C490.952%2C600.539%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%226%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/EIWKIWKF?page=6&#x26;annotation=MBPDCBJG">“We assume an affine camera model and implement the Gold Standard Algorithm of Hartley &#x26; Zisserman (Hartley and Zisserman, 2004)”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/4GDBRS3R">Huber et al., 2016, p. 6</a></span>)</span> 🔤我们假设一个仿射摄像头模型并实施了Hartley＆Zisserman的黄金标准算法（Hartley and Zisserman，2004年）🔤

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2FEIWKIWKF%22%2C%22annotationKey%22%3A%22CRNKAMNQ%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B129.353%2C392.911%2C286.32%2C401.818%5D%2C%5B73.701%2C381.454%2C286.323%2C390.361%5D%2C%5B73.701%2C369.997%2C186.697%2C378.904%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%227%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/EIWKIWKF?page=7&#x26;annotation=CRNKAMNQ">“vertex_indices are obtained with the supplied landmark annotation metadata and the mapping facilities of the library”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12198786%2Fitems%2F4GDBRS3R%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/4GDBRS3R">Huber et al., 2016, p. 7</a></span>)</span> 🔤Vertex\_Indices是通过提供的具有里程碑意义的注释元数据和图书馆的映射设施获得的🔤
